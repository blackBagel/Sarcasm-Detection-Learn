{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarcasm_detection-simple_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackBagel/Sarcasm-Detection-Learn/blob/main/sarcasm_detection_simple_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqllYLjHrLXf",
        "outputId": "ec24ba6b-51ce-42ff-c181-df5625aff0d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "! pip install -U eli5 clean-text"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: eli5 in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already up-to-date: clean-text in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.2)\n",
            "Requirement already satisfied, skipping upgrade: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (20.2.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: ftfy<6.0,>=5.8 in /usr/local/lib/python3.6/dist-packages (from clean-text) (5.8)\n",
            "Requirement already satisfied, skipping upgrade: emoji in /usr/local/lib/python3.6/dist-packages (from clean-text) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<6.0,>=5.8->clean-text) (0.2.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Azf7jp10cF"
      },
      "source": [
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "import re\n",
        "from cleantext import clean\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn import preprocessing, decomposition, model_selection, pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import eli5\n",
        "import pickle\n",
        "from time import perf_counter\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo17lJdKI2U3"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwDkTHa3IXTV",
        "outputId": "1c2dfb0b-fc25-441f-f8a1-40e8047ba32d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "DRIVE_PATH = '/gdrive/My Drive/Reddit sarcasm'\n",
        "drive.mount('/gdrive')\n",
        "os.chdir(DRIVE_PATH)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_G25c4LINkx"
      },
      "source": [
        "DATA_COLUMNS = [\n",
        "    'label',\n",
        "    'comment',\n",
        "    'author',\n",
        "    'subreddit',\n",
        "    'score',\n",
        "    'ups',\n",
        "    'downs',\n",
        "    'date',\n",
        "    'created_utc',\n",
        "    'parent_comment'\n",
        "]\n",
        "\n",
        "full_comments_df = pd.read_csv(\"train-balanced-sarc.csv\", delimiter='\\t', names=DATA_COLUMNS)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqR8bwMI93PU"
      },
      "source": [
        "## Methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmnNj35QuNTH"
      },
      "source": [
        "First, let's see the data distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki7ZyPskuWad",
        "outputId": "0a335d37-d864-4623-ccdd-e29c33d71910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "full_comments_df.plot(kind='hist', y='label', title = 'Labels Distribution')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4f9c6d2198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp8nmrUIw1XY"
      },
      "source": [
        "The data is balanced with regard to the labels. Therefore, I'll use the accuracy metric to evaluate all future models.\n",
        "\n",
        "I prefer to evaluate all the models based primarily on accuracy. The data is well balanced and there is no actual buisiness problem i'm solving here, so there's not much of a need to specifically avoid either FPs or FNs.\n",
        "\n",
        "I will however keep the precision and recall scores of all models for future reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAad69rm_5O-"
      },
      "source": [
        "#### Train-Validation-Test Split "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ibCkqKJ88wY"
      },
      "source": [
        "The dataset is quite relatively large with about 1 million comments. For that reason, it is quite reasonable to use only 4% of the data as test and validation sets, since they'll still be 20k each.\n",
        "\n",
        "That way, we'll have lots of data to train on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX7ct9oLXFH2"
      },
      "source": [
        "TRAIN_VAL_RAND_STATE = 1\n",
        "VAL_TEST_RAND_STATE = 5\n",
        "TRAIN_TEST_SPLIT = 0.04\n",
        "VAL_TEST_SPLIT = 0.5\n",
        "\n",
        "comments_df_without_labels = full_comments_df.iloc[:, 1:]\n",
        "\n",
        "# We use the same train-test split to test all of the next models\n",
        "df_train, df_test, labels_train, labels_test = train_test_split(comments_df_without_labels,\n",
        "                                                                full_comments_df['label'],\n",
        "                                                                random_state=TRAIN_VAL_RAND_STATE,\n",
        "                                                                test_size=TRAIN_TEST_SPLIT,\n",
        "                                                                shuffle=True)\n",
        "\n",
        "df_val, df_test, labels_val, labels_test = train_test_split(df_test,\n",
        "                                                            labels_test,\n",
        "                                                            random_state=VAL_TEST_RAND_STATE,\n",
        "                                                            test_size=VAL_TEST_SPLIT,\n",
        "                                                            shuffle=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TgiVb7wNQjc"
      },
      "source": [
        "Let's make sure the validation and test set have similar distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSuOoIfwCRko",
        "outputId": "2f5366a5-8a18-486e-f856-83b1be5fba14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1,ncols=2,figsize=(8,4))\n",
        "\n",
        "labels_val.plot.hist(ax = axes[0], title='Validation Labels')\n",
        "labels_test.plot.hist(ax = axes[1], title='Test Labels')\n",
        "fig.tight_layout()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnUmivNMFlIC"
      },
      "source": [
        "#### Null handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaU1cGgkVTTr",
        "outputId": "b9bca042-2b52-4e89-f14c-99ee487acfe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print(\"Nulls in training set:\")\n",
        "df_train.isnull().sum()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nulls in training set:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "comment           51\n",
              "author             0\n",
              "subreddit          0\n",
              "score              0\n",
              "ups                0\n",
              "downs              0\n",
              "date               0\n",
              "created_utc        0\n",
              "parent_comment     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlTUZog0s7IZ"
      },
      "source": [
        "Since I don't want to divide and reassemble the data and the labels each time i apply a function to both, i'll simply create a function that applies row based functions to them and handles the dividing and reassembling for me"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBZwEjEYdxFj"
      },
      "source": [
        "def handle_row_dropping_functions(df, labels, row_dropping_funcs={}):\n",
        "  \"\"\"\n",
        "  Applies data munging functions that may drop rows in the dataset\n",
        "  This function makes sure the corresponding labels of each dropped row is deleted as well\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df : pandas DataFrame\n",
        "      The dataset to apply the functions on\n",
        "  labels : pandas Series\n",
        "      The corresponding labels of the dataset\n",
        "  row_dropping_funcs : Dict\n",
        "      A dictionary containing functions as keys\n",
        "      and any parameters necessary for them (except the df!) as values\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  new_df\n",
        "      The recieved DF after being handled the fucntions\n",
        "  new_labels:\n",
        "      The labels for the df, without the dropped rows\n",
        "  \"\"\"\n",
        "\n",
        "  # Combine data and labels based on their index\n",
        "  new_df = df.copy()\n",
        "  new_labels = labels.copy()\n",
        "  new_df['label'] = new_labels\n",
        "  \n",
        "  # Apply row dropping functions\n",
        "  for row_dropping_func, func_params in row_dropping_funcs.items():\n",
        "    func_params['df'] = new_df\n",
        "    new_df = row_dropping_func(**func_params)\n",
        "  \n",
        "  # Return the updated datasets as they were before\n",
        "  new_labels = new_df['label']\n",
        "  new_df = new_df.drop(columns = ['label'])\n",
        "\n",
        "  return new_df, new_labels"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-cgrlu4OKxT"
      },
      "source": [
        "def handle_nulls(**kwargs):\n",
        "  \"\"\"\n",
        "  Returns the df without rows where some columns are null\n",
        "  Right now could have been done without a function,\n",
        "  but useful for encapsulating more complex null handling situations in the future\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df : pandas DataFrame\n",
        "      The dataset to drop NaNs from\n",
        "  unfixable_columns : list\n",
        "      The columns that need to be dropped if empty (default is an empty list)\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  new_df\n",
        "      The recieved DF but with rows without null columns\n",
        "  \"\"\"\n",
        "\n",
        "  new_df = kwargs['df'].copy()\n",
        "  new_df = new_df.dropna(subset = kwargs['unfixable_columns'])\n",
        "  return new_df"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbwwENfYdATn"
      },
      "source": [
        "def nan_handle(df, labels):\n",
        "  new_df = df.copy()\n",
        "  new_labels = labels.copy()\n",
        "\n",
        "  # If the value of these columns is null, drop the row \n",
        "  COLUMNS_TO_DROP_BY = ['comment']\n",
        "\n",
        "  row_dropping_funcs = {\n",
        "      handle_nulls: { 'unfixable_columns': COLUMNS_TO_DROP_BY }\n",
        "      }\n",
        "\n",
        "  new_df, new_labels = handle_row_dropping_functions(new_df, new_labels, row_dropping_funcs)\n",
        "  return new_df, new_labels"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeT_OluY8I3G"
      },
      "source": [
        "#### Text cleaning - Comments only\n",
        "\n",
        "For starters, i'll only explore the comments themselves to see how much sarcasm can be inferred from the text alone.\n",
        "\n",
        "Later on i'll start engineering more features from the rest of the data to see how much the context matters for inferring sarcasm with this data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPlExkPR9pfX"
      },
      "source": [
        "Let's look at a sample from the text to see what we're handling with"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOqAE9M28NM_",
        "outputId": "9c703edd-298b-4a9e-9e89-d4b8be7fa157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for index, text in enumerate(df_train['comment'][35:40]):\n",
        "  print('Comment {}:\\n {}'.format(index+1, text))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comment 1:\n",
            " That Stormtrooper pumpkin looks awesome!\n",
            "Comment 2:\n",
            " Yeah, Barry will let this slide.\n",
            "Comment 3:\n",
            " Uh oh, Trigga Trey gonna get some revenge.\n",
            "Comment 4:\n",
            " fuck your opinion\n",
            "Comment 5:\n",
            " we know, but not to loud or the wackos will catch on\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z37Wec8J4Hi",
        "outputId": "60a32c81-92ad-4b53-8e85-25833be888cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>author</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>score</th>\n",
              "      <th>ups</th>\n",
              "      <th>downs</th>\n",
              "      <th>date</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>parent_comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62983</th>\n",
              "      <td>Agree with ya, it runs better on my 6years old...</td>\n",
              "      <td>GFlunk</td>\n",
              "      <td>PS3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-09</td>\n",
              "      <td>1474168109</td>\n",
              "      <td>I have that one. It sucks.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630544</th>\n",
              "      <td>Yeah, she works me like a rented mule every mo...</td>\n",
              "      <td>comaboy13</td>\n",
              "      <td>MMA</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-07</td>\n",
              "      <td>1436594373</td>\n",
              "      <td>That's really good to know, she'll need it if ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953886</th>\n",
              "      <td>Context?</td>\n",
              "      <td>BigBud77</td>\n",
              "      <td>pics</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2013-05</td>\n",
              "      <td>1367543886</td>\n",
              "      <td>His best friend left today. Not sure if they w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287968</th>\n",
              "      <td>Better quality and without this shit music on ...</td>\n",
              "      <td>Superdraw</td>\n",
              "      <td>formula1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05</td>\n",
              "      <td>1462484952</td>\n",
              "      <td>Albers pulls off an a stunning move (Estoril 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972967</th>\n",
              "      <td>I'm so glad some redditors have taken it upon ...</td>\n",
              "      <td>BuyABowel</td>\n",
              "      <td>MensRights</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-03</td>\n",
              "      <td>1331746883</td>\n",
              "      <td>Explanation requested in AskReddit about r/men...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  comment  ...                                     parent_comment\n",
              "62983   Agree with ya, it runs better on my 6years old...  ...                         I have that one. It sucks.\n",
              "630544  Yeah, she works me like a rented mule every mo...  ...  That's really good to know, she'll need it if ...\n",
              "953886                                           Context?  ...  His best friend left today. Not sure if they w...\n",
              "287968  Better quality and without this shit music on ...  ...  Albers pulls off an a stunning move (Estoril 2...\n",
              "972967  I'm so glad some redditors have taken it upon ...  ...  Explanation requested in AskReddit about r/men...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAv1n5EEVHLX"
      },
      "source": [
        "NLP_ENGINES = {\n",
        "    'simple' : spacy.load(\"en_core_web_sm\", disable=['tagger', 'parser', 'ner']),\n",
        "    'POSs_and_deps' : spacy.load(\"en_core_web_sm\", disable=['ner'])\n",
        "}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjy2NRjl3SST"
      },
      "source": [
        "def tokenize_and_clean_text(doc):\n",
        "  tokenized_processed_text = []\n",
        "  for token in doc: \n",
        "    cleaned_text = token.text.lower()\n",
        "    if token.is_currency:\n",
        "      cleaned_text = clean(cleaned_text, no_currency_symbols = True)\n",
        "    if token.is_digit:\n",
        "      cleaned_text = clean(cleaned_text, no_numbers = True)\n",
        "    if token.like_email:\n",
        "      cleaned_text = clean(cleaned_text, no_emails = True)\n",
        "    if token.like_url:\n",
        "      cleaned_text = clean(cleaned_text, no_urls = True)\n",
        "    \n",
        "    tokenized_processed_text.append(cleaned_text)\n",
        "  \n",
        "  return tokenized_processed_text"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weaHzGQSNi0V"
      },
      "source": [
        "def simple_text_processing(text):\n",
        "  # spaCy will only handle contractions and will just tokenize the data in general\n",
        "  nlp_engine = NLP_ENGINES['simple']\n",
        "  doc = nlp_engine(text)\n",
        "\n",
        "  ############################ TBD\n",
        "  # Somewhere along the way, the returned list's objects are objects that are not strings per ce...\n",
        "  # A conversion here solves it, but it's probably worth investigating in the future\n",
        "  return str(tokenize_and_clean_text(doc))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5cNehPtPlgU"
      },
      "source": [
        "def add_simple_processing_columns(df, from_where='scratch', file_path = None):\n",
        "  new_df = df.copy()\n",
        "  if file_path is not None: \n",
        "    if from_where == 'scratch':\n",
        "      new_df['processed comment'] = new_df['comment'].apply(lambda comment: simple_text_processing(comment))\n",
        "      new_df.to_csv(file_path)\n",
        "    elif from_where == 'file':\n",
        "      new_df_processed = pd.read_csv(file_path, usecols = ['processed comment'])\n",
        "      new_df_processed.index = new_df.index\n",
        "      new_df = new_df.merge(new_df_processed, how='left', left_index = True, right_index = True) \n",
        "    else:\n",
        "      print('No new features. You haven\\'t entered a valid feature source')\n",
        "\n",
        "  return new_df"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUqsYI4MHXQo"
      },
      "source": [
        "def preprocess_df(df, labels, extra_features_from, extra_features_file_path):\n",
        "  new_df = df.copy()\n",
        "  new_labels = labels.copy()  \n",
        "\n",
        "  new_df, new_labels = nan_handle(new_df, new_labels)\n",
        "  new_df = add_simple_processing_columns(new_df,\n",
        "                                         from_where = extra_features_from,\n",
        "                                         file_path = extra_features_file_path)\n",
        "\n",
        "  return new_df, new_labels"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_uZf5JgHSk3"
      },
      "source": [
        "full_df_train_for_clf, labels_train_for_clf = preprocess_df(df_train, labels_train,\n",
        "                                                            extra_features_from = 'file',\n",
        "                                                            extra_features_file_path = 'POSs_and_deps_for_train_state_1.csv')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2KdKs6XXXHP",
        "outputId": "27ba88e2-e909-4831-f062-7d8a80cd527f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for index, text in enumerate(full_df_train_for_clf['processed comment'][35:40]):\n",
        "  print('Comment {}:\\n {}'.format(index+1, text))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comment 1:\n",
            " ['that', 'stormtrooper', 'pumpkin', 'looks', 'awesome', '!']\n",
            "Comment 2:\n",
            " ['yeah', ',', 'barry', 'will', 'let', 'this', 'slide', '.']\n",
            "Comment 3:\n",
            " ['uh', 'oh', ',', 'trigga', 'trey', 'gon', 'na', 'get', 'some', 'revenge', '.']\n",
            "Comment 4:\n",
            " ['fuck', 'your', 'opinion']\n",
            "Comment 5:\n",
            " ['we', 'know', ',', 'but', 'not', 'to', 'loud', 'or', 'the', 'wackos', 'will', 'catch', 'on']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEskcbTYJfqH"
      },
      "source": [
        "# Model Research Process - Comments Only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjhEt9PYEwHH"
      },
      "source": [
        "#### Preprocess the validation and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJNIPpKuJfUm"
      },
      "source": [
        "full_df_val_for_clf, labels_val_for_clf = preprocess_df(df_val, labels_val,\n",
        "                                                   extra_features_from = 'file',\n",
        "                                                   extra_features_file_path = 'validation_processed_for_rand_state_{}.csv'.format(VAL_TEST_RAND_STATE))\n",
        "full_df_test_for_clf, labels_test_for_clf = preprocess_df(df_test, labels_test,\n",
        "                                                     extra_features_from = 'file',\n",
        "                                                     extra_features_file_path = 'test_processed_for_rand_state_{}.csv'.format(VAL_TEST_RAND_STATE))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFvpouHVJjG7"
      },
      "source": [
        "## We begin our research by trying out a basic logistic regression model on only a simple tokenized comment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU4Bn3dF35cf"
      },
      "source": [
        "FEATURES_TO_CLASSIFY_BY = ['processed comment']\n",
        "df_train_for_clf = full_df_train_for_clf[FEATURES_TO_CLASSIFY_BY]\n",
        "df_val_for_clf = full_df_val_for_clf[FEATURES_TO_CLASSIFY_BY]\n",
        "df_test_for_clf = full_df_test_for_clf[FEATURES_TO_CLASSIFY_BY]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWfnvrvOAhO6"
      },
      "source": [
        "TEXTUAL_COLUMNS = 'processed comment'\n",
        "model_pipes_to_evaluate = {}\n",
        "MODELS_FOLDER = './models'"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9IzfoDNMW12"
      },
      "source": [
        "def save_model_pipeline_and_info(model_pipe_and_info, file_name):\n",
        "  full_path = os.path.join(MODELS_FOLDER, file_name)\n",
        "  with open(full_path, 'wb') as model_pipeline_and_info_file:\n",
        "    pickle.dump(model_pipe_and_info, model_pipeline_and_info_file)\n",
        "            \n",
        "def get_model_pipeline_and_info(file_name):\n",
        "  full_path = os.path.join(MODELS_FOLDER, file_name)\n",
        "  if os.path.exists(full_path):\n",
        "    with open(full_path, 'rb') as model_pipeline_and_info_file:\n",
        "      model_pipe_and_info = pickle.load(model_pipeline_and_info_file)\n",
        "  else:\n",
        "      return None\n",
        "  return model_pipe_and_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhCmO3fvV3lE"
      },
      "source": [
        "### First, a relatively primitive count vectorizer of the comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "961AIbjXWYpT"
      },
      "source": [
        "# I'll assume a word that doesn't appear at least thrice, is probably too specific to care about\n",
        "ctv = CountVectorizer(min_df = 3)\n",
        "text_preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', ctv, TEXTUAL_COLUMNS)\n",
        "    ])\n",
        "log_reg_ctv_clf = LogisticRegression(solver='saga', C=1, n_jobs=-1, verbose=False, max_iter=300)\n",
        "ctv_lr_pipeline = Pipeline([('counter', text_preprocessor), \n",
        "                            ('logitRegressor', log_reg_ctv_clf)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79CZ5F5UWZ_Z",
        "outputId": "8536523c-2ed6-4576-f6d2-d8606a4f874f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "%%time\n",
        "ctv_lr_pipeline.fit(df_train_for_clf, labels_train_for_clf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6min 6s, sys: 359 ms, total: 6min 6s\n",
            "Wall time: 4min 41s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('counter',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('text',\n",
              "                                                  CountVectorizer(analyzer='word',\n",
              "                                                                  binary=False,\n",
              "                                                                  decode_error='strict',\n",
              "                                                                  dtype=<class 'numpy.int64'>,\n",
              "                                                                  encoding='utf-8',\n",
              "                                                                  input='content',\n",
              "                                                                  lowercase=True,\n",
              "                                                                  max_df=1.0,\n",
              "                                                                  max_features=None,\n",
              "                                                                  min_df=3,\n",
              "                                                                  ngram_range=(1,\n",
              "                                                                               1...\n",
              "                                                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                                                  tokenizer=None,\n",
              "                                                                  vocabulary=None),\n",
              "                                                  'processed comment')],\n",
              "                                   verbose=False)),\n",
              "                ('logitRegressor',\n",
              "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=300,\n",
              "                                    multi_class='auto', n_jobs=-1, penalty='l2',\n",
              "                                    random_state=None, solver='saga',\n",
              "                                    tol=0.0001, verbose=False,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrADpSmwWzsb",
        "outputId": "6b4182fd-3b83-4336-8912-b3c297200e46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Logistic Regressor has a ready score function that returns the accuracy of the model on another dataset\n",
        "print (\"Training accuracy: %0.5f \" % ctv_lr_pipeline.score(df_train_for_clf, labels_train_for_clf))\n",
        "print (\"Validation accuracy: %0.5f \" % ctv_lr_pipeline.score(df_val_for_clf, labels_val_for_clf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.64346 \n",
            "Validation accuracy: 0.63717 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hBZQyhDXZqV"
      },
      "source": [
        "### We also test a basic tf-idf vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UkKmNJ8KytE"
      },
      "source": [
        "# We'll first try to create a simple baseline model\n",
        "# Our baseline model will be a logistic regression model, which we'll train on the unigram tf_idf vectors of the original comments text \n",
        "tfv = TfidfVectorizer(min_df = 3)\n",
        "text_preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', tfv, TEXTUAL_COLUMNS)\n",
        "    ])\n",
        "lr_tfidf_clf = LogisticRegression(solver='saga', n_jobs=-1, verbose=False, max_iter=300)\n",
        "\n",
        "tfidf_lr_pipeline = Pipeline([('tf_idf', text_preprocessor), \n",
        "                                 ('logitRegressor', lr_tfidf_clf)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbcU2CtBlLGa",
        "outputId": "0530abdf-3e2e-4ad4-bae0-7e6252c241f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "%%time\n",
        "tfidf_lr_pipeline.fit(df_train_for_clf, labels_train_for_clf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 34.6 s, sys: 28 ms, total: 34.7 s\n",
            "Wall time: 34.7 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tf_idf',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('text',\n",
              "                                                  TfidfVectorizer(analyzer='word',\n",
              "                                                                  binary=False,\n",
              "                                                                  decode_error='strict',\n",
              "                                                                  dtype=<class 'numpy.float64'>,\n",
              "                                                                  encoding='utf-8',\n",
              "                                                                  input='content',\n",
              "                                                                  lowercase=True,\n",
              "                                                                  max_df=1.0,\n",
              "                                                                  max_features=None,\n",
              "                                                                  min_df=3,\n",
              "                                                                  ngram_range=(1,...\n",
              "                                                                  tokenizer=None,\n",
              "                                                                  use_idf=True,\n",
              "                                                                  vocabulary=None),\n",
              "                                                  'processed comment')],\n",
              "                                   verbose=False)),\n",
              "                ('logitRegressor',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=300,\n",
              "                                    multi_class='auto', n_jobs=-1, penalty='l2',\n",
              "                                    random_state=None, solver='saga',\n",
              "                                    tol=0.0001, verbose=False,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkaRSFgSlNh0",
        "outputId": "84e96ad4-1198-4109-c2d0-686d46fcd86b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print (\"Training accuracy: %0.5f \" % tfidf_lr_pipeline.score(df_train_for_clf, labels_train_for_clf))\n",
        "print (\"Validation accuracy: %0.5f \" % tfidf_lr_pipeline.score(df_val_for_clf, labels_val_for_clf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.71713 \n",
            "Validation accuracy: 0.69158 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJY5hYrFXgrG"
      },
      "source": [
        "### We try a more sophisticated tf-idf vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDp5qv7mLQaq"
      },
      "source": [
        "# Now let's try to run the same model, but on a more sophisticated tf-idf \n",
        "# This vectorizor is trained on both unigrams and bigrams, and only considers words that were used at least twice\n",
        "tfv = TfidfVectorizer(ngram_range=(1, 2), min_df=3)\n",
        "text_preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', tfv, TEXTUAL_COLUMNS)\n",
        "    ])\n",
        "lr_tfidf_clf = LogisticRegression(solver='saga', n_jobs=-1, verbose=False, max_iter=300)\n",
        "\n",
        "tfidf_lr_pipeline = Pipeline([('tf_idf', text_preprocessor), \n",
        "                              ('logitRegressor', lr_tfidf_clf)])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BmVM_nWVEjb",
        "outputId": "b3458c54-eefb-4efb-cfa3-4253455e9ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "%%time\n",
        "tfidf_lr_pipeline.fit(df_train_for_clf, labels_train_for_clf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 13s, sys: 850 ms, total: 1min 14s\n",
            "Wall time: 1min 14s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tf_idf',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('text',\n",
              "                                                  TfidfVectorizer(analyzer='word',\n",
              "                                                                  binary=False,\n",
              "                                                                  decode_error='strict',\n",
              "                                                                  dtype=<class 'numpy.float64'>,\n",
              "                                                                  encoding='utf-8',\n",
              "                                                                  input='content',\n",
              "                                                                  lowercase=True,\n",
              "                                                                  max_df=1.0,\n",
              "                                                                  max_features=None,\n",
              "                                                                  min_df=3,\n",
              "                                                                  ngram_range=(1,...\n",
              "                                                                  tokenizer=None,\n",
              "                                                                  use_idf=True,\n",
              "                                                                  vocabulary=None),\n",
              "                                                  'processed comment')],\n",
              "                                   verbose=False)),\n",
              "                ('logitRegressor',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=300,\n",
              "                                    multi_class='auto', n_jobs=-1, penalty='l2',\n",
              "                                    random_state=None, solver='saga',\n",
              "                                    tol=0.0001, verbose=False,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eefMkLZWVGDB",
        "outputId": "79aae77a-1b7c-45f9-b759-a9dae4bc3059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print (\"Training accuracy: %0.5f \" % tfidf_lr_pipeline.score(df_train_for_clf, labels_train_for_clf))\n",
        "print (\"Validation accuracy: %0.5f \" % tfidf_lr_pipeline.score(df_val_for_clf, labels_val_for_clf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.78497 \n",
            "Validation accuracy: 0.72373 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqOkWA0NVTBI",
        "outputId": "5bad085b-1513-4334-f096-0bd6bdfe647a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        }
      },
      "source": [
        "# Because it was te best model we tried to understand better what affected his performance\n",
        "eli5.show_weights(estimator=tfidf_lr_pipeline.named_steps['logitRegressor'],\n",
        "                  vec=tfidf_lr_pipeline.named_steps['tf_idf'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "            \n",
              "                \n",
              "                \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1\n",
              "    \n",
              "</b>\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
              "                    Weight<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +10.494\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__yes because\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 82.06%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +8.981\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__obviously\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 82.32%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +8.798\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__clearly\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 82.98%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +8.336\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__totally\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 82.98%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +8.335\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__yeah because\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 83.12%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +8.237\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__because\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 85.08%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +6.903\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__how dare\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 85.92%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +6.356\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__good thing\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.32%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +6.100\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__right because\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.91%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.725\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__gee\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.93%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.717\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__duh\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 87.12%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.594\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__but thought\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 87.18%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.561\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__fault\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 87.31%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.477\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__therefore\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 87.63%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.283\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__yeah fuck\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 87.90%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.116\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__shitlord\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 87.95%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.091\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__or anything\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 88.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.057\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__everyone knows\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 88.00%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 199169 more positive &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 88.11%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 187069 more negative &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 88.11%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -4.989\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__true but\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.53%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -5.341\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        text__iirc\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "            \n",
              "        \n",
              "\n",
              "        \n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grzSqsZ29FeO"
      },
      "source": [
        "So using tf-idf with bi-grams and a minimum df count of 3 seems to be a good representation for the data for now.\n",
        "\n",
        "Later on i'll try to use embeddings too and see if they add any significant gains"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG_KhIK6Faso"
      },
      "source": [
        "#### Let's save this model as the best one for now, and move on to more sophisticated classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbqJgSBf_KW0"
      },
      "source": [
        "scores = {\n",
        "  'Training' : 0.78497,\n",
        "  'Validation' : 0.72373,\n",
        "  'Test' : 0.72621 # Calculated this on another run\n",
        "}\n",
        "best_model_so_far = {\n",
        "    'name' : 'tf-idf bi-gram min-df-3 logit-regressor', # Name of the model\n",
        "    'pipeline_and_params' : (tfidf_lr_pipeline, {}), # A tuple containing a sklearn.Pipeline object and a parameters dict\n",
        "    'scores' : scores, # A dict of scores on each dataset\n",
        "    'time' : 74 # Training time in seconds\n",
        "}"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7g1BI3GOXHs"
      },
      "source": [
        "save_model_pipeline_and_info(best_model_so_far, file_name='best_model_so_far.pickle')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFIMe5oYFu16"
      },
      "source": [
        "## Using better Classifiers on a Bi-Gram Tf-Idf with min_df of 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P7qyGp6qQ4C"
      },
      "source": [
        "def evaluate_model_pipelines(model_pipelines):\n",
        "  for name, (model_pipeline, fit_params) in model_pipelines.items():\n",
        "    print('\\n###########################################################################')\n",
        "    print('# Model type: {}'.format(name))\n",
        "    print('###########################################################################')\n",
        "    \n",
        "    # Train the model\n",
        "    fit_start = perf_counter()\n",
        "    model_pipeline.fit(df_train_for_clf, labels_train_for_clf, **fit_params)\n",
        "    fit_end = perf_counter()\n",
        "\n",
        "    # plot_model_performance(model_history)\n",
        "    \n",
        "    # Calculate the current model's performance and time\n",
        "    # fit time is in seconds\n",
        "    fit_time = fit_end - fit_start\n",
        "    fit_time_hours = int(fit_time / 60 / 60)\n",
        "    fit_time_minutes = int(fit_time / 60 )\n",
        "    fit_time_seconds = int(fit_time % 60)\n",
        "\n",
        "    print(\"Training time: {} hours, {} minutes, {} seconds\".format(fit_time_hours, fit_time_minutes, fit_time_seconds))\n",
        "\n",
        "    scores = {\n",
        "        'Training' : model_pipeline.score(df_train_for_clf, labels_train_for_clf),\n",
        "        'Validation' : model_pipeline.score(df_val_for_clf, labels_val_for_clf),\n",
        "        'Test' : model_pipeline.score(df_test_for_clf, labels_test_for_clf)\n",
        "        }\n",
        "    for dataset_type, score in scores.items():\n",
        "      print (\"%s accuracy: %0.5f \" % (dataset_type, score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOdsJmImwkKp",
        "outputId": "33bdafcf-d27c-4f2b-c54a-9bb36cbabe44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "evaluate_model_pipelines(model_pipes_to_evaluate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "###########################################################################\n",
            "# Model type: tf-idf_bi-gram_min-df-3_logit-regressor\n",
            "###########################################################################\n",
            "Training time: 0 hours, 1 minutes, 71 seconds\n",
            "Training accuracy: 0.78497 \n",
            "Validation accuracy: 0.72373 \n",
            "Test accuracy: 0.72621 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}