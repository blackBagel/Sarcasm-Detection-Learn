{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarcasm_detection-simple_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackBagel/Sarcasm-Detection-Learn/blob/main/sarcasm_detection_simple_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqllYLjHrLXf",
        "outputId": "34e36b9c-d22c-4884-855b-bfa1cde6e367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "! pip install -U eli5 clean-text"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 3.5MB/s \n",
            "\u001b[?25hCollecting clean-text\n",
            "  Downloading https://files.pythonhosted.org/packages/78/30/7013e9bf37e00ad81406c771e8f5b071c624b8ab27a7984cd9b8434bed4f/clean_text-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.2)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (20.2.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Collecting ftfy<6.0,>=5.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.0MB/s \n",
            "\u001b[?25hCollecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<6.0,>=5.8->clean-text) (0.2.5)\n",
            "Building wheels for collected packages: ftfy, emoji\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45612 sha256=bd3ecdde8bb10f70c5e56b17ef747302e4dd26cb2bc5a2eb7fd92af112442568\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.6.0-cp36-none-any.whl size=49716 sha256=2f759a8b8631be3b2e7f71c872cf0dd6ceb34cc09236ee8d3902941c00076006\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n",
            "Successfully built ftfy emoji\n",
            "Installing collected packages: eli5, ftfy, emoji, clean-text\n",
            "Successfully installed clean-text-0.3.0 eli5-0.10.1 emoji-0.6.0 ftfy-5.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Azf7jp10cF",
        "outputId": "72806fc9-39e1-4abe-da13-9d3b8f98dfc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "import re\n",
        "from cleantext import clean\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn import preprocessing, decomposition, model_selection, pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import eli5\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo17lJdKI2U3"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwDkTHa3IXTV",
        "outputId": "3df7da95-e3ce-4725-deae-4bbf8f55ea9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "DRIVE_PATH = '/gdrive/My Drive/Reddit sarcasm'\n",
        "drive.mount('/gdrive')\n",
        "os.chdir(DRIVE_PATH)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_G25c4LINkx"
      },
      "source": [
        "DATA_COLUMNS = [\n",
        "    'label',\n",
        "    'comment',\n",
        "    'author',\n",
        "    'subreddit',\n",
        "    'score',\n",
        "    'ups',\n",
        "    'downs',\n",
        "    'date',\n",
        "    'created_utc',\n",
        "    'parent_comment'\n",
        "]\n",
        "\n",
        "full_comments_df = pd.read_csv(\"train-balanced-sarc.csv\", delimiter='\\t', names=DATA_COLUMNS)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqR8bwMI93PU"
      },
      "source": [
        "## Methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmnNj35QuNTH"
      },
      "source": [
        "First, let's see the data distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki7ZyPskuWad",
        "outputId": "3c4e53ef-cbbc-4431-823b-182b86638bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "full_comments_df.plot(kind='hist', y='label', title = 'Labels Distribution')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9b291821d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp8nmrUIw1XY"
      },
      "source": [
        "The data is balanced with regard to the labels. Therefore, I'll use the accuracy metric to evaluate all future models.\n",
        "\n",
        "I prefer to evaluate all the models based primarily on accuracy. The data is well balanced and there is no actual buisiness problem i'm solving here, so there's not much of a need to specifically avoid either FPs or FNs.\n",
        "\n",
        "I will however keep the precision and recall scores of all models for future reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAad69rm_5O-"
      },
      "source": [
        "#### Train-Validation-Test Split "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ibCkqKJ88wY"
      },
      "source": [
        "The dataset is quite relatively large with about 1 million comments. For that reason, it is quite reasonable to use only 4% of the data as test and validation sets, since they'll still be 20k each.\n",
        "\n",
        "That way, we'll have lots of data to train on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX7ct9oLXFH2"
      },
      "source": [
        "comments_df_without_labels = full_comments_df.iloc[:, 1:]\n",
        "\n",
        "# We use the same train-test split to test all of the next models\n",
        "df_train, df_test, labels_train, labels_test = train_test_split(comments_df_without_labels,\n",
        "                                                                full_comments_df['label'],\n",
        "                                                                random_state=1,\n",
        "                                                                test_size=0.04,\n",
        "                                                                shuffle=True)\n",
        "\n",
        "df_val, df_test, labels_val, labels_test = train_test_split(df_test,\n",
        "                                                            labels_test,\n",
        "                                                            random_state=5,\n",
        "                                                            test_size=0.5,\n",
        "                                                            shuffle=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TgiVb7wNQjc"
      },
      "source": [
        "Let's make sure the validation and test set have similar distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSuOoIfwCRko",
        "outputId": "257d1cf8-c4f2-44fb-d3bd-b00e4ef75304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1,ncols=2,figsize=(8,4))\n",
        "\n",
        "labels_val.plot.hist(ax = axes[0], title='Validation Labels')\n",
        "labels_test.plot.hist(ax = axes[1], title='Test Labels')\n",
        "fig.tight_layout()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnUmivNMFlIC"
      },
      "source": [
        "#### Null handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaU1cGgkVTTr",
        "outputId": "daace3b9-15e9-406a-8476-c812c172dc2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print(\"Nulls in training set:\")\n",
        "df_train.isnull().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nulls in training set:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "comment           51\n",
              "author             0\n",
              "subreddit          0\n",
              "score              0\n",
              "ups                0\n",
              "downs              0\n",
              "date               0\n",
              "created_utc        0\n",
              "parent_comment     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlTUZog0s7IZ"
      },
      "source": [
        "Since I don't want to divide and reassemble the data and the labels each time i apply a function to both, i'll simply create a function that applies row based functions to them and handles the dividing and reassembling for me"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBZwEjEYdxFj"
      },
      "source": [
        "def handle_row_dropping_functions(df, labels, row_dropping_funcs={}):\n",
        "  \"\"\"\n",
        "  Applies data munging functions that may drop rows in the dataset\n",
        "  This function makes sure the corresponding labels of each dropped row is deleted as well\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df : pandas DataFrame\n",
        "      The dataset to apply the functions on\n",
        "  labels : pandas Series\n",
        "      The corresponding labels of the dataset\n",
        "  row_dropping_funcs : Dict\n",
        "      A dictionary containing functions as keys\n",
        "      and any parameters necessary for them (except the df!) as values\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  new_df\n",
        "      The recieved DF after being handled the fucntions\n",
        "  new_labels:\n",
        "      The labels for the df, without the dropped rows\n",
        "  \"\"\"\n",
        "\n",
        "  # Combine data and labels based on their index\n",
        "  new_df = df.copy()\n",
        "  new_labels = labels.copy()\n",
        "  new_df['label'] = new_labels\n",
        "  \n",
        "  # Apply row dropping functions\n",
        "  for row_dropping_func, func_params in row_dropping_funcs.items():\n",
        "    func_params['df'] = new_df\n",
        "    new_df = row_dropping_func(**func_params)\n",
        "  \n",
        "  # Return the updated datasets as they were before\n",
        "  new_labels = new_df['label']\n",
        "  new_df = new_df.drop(columns = ['label'])\n",
        "\n",
        "  return new_df, new_labels"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-cgrlu4OKxT"
      },
      "source": [
        "def handle_nulls(**kwargs):\n",
        "  \"\"\"\n",
        "  Returns the df without rows where some columns are null\n",
        "  Right now could have been done without a function,\n",
        "  but useful for encapsulating more complex null handling situations in the future\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  df : pandas DataFrame\n",
        "      The dataset to drop NaNs from\n",
        "  unfixable_columns : list\n",
        "      The columns that need to be dropped if empty (default is an empty list)\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  new_df\n",
        "      The recieved DF but with rows without null columns\n",
        "  \"\"\"\n",
        "\n",
        "  new_df = kwargs['df'].copy()\n",
        "  new_df = new_df.dropna(subset = kwargs['unfixable_columns'])\n",
        "  return new_df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbwwENfYdATn",
        "outputId": "3fc604d0-89aa-4796-ef47-7df16c635ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# If the value of these columns is null, drop the row \n",
        "COLUMNS_TO_DROP_BY = ['comment']\n",
        "\n",
        "row_dropping_funcs = {\n",
        "    handle_nulls: { 'unfixable_columns': COLUMNS_TO_DROP_BY }\n",
        "    }\n",
        "\n",
        "df_train, labels_train = handle_row_dropping_functions(df_train, labels_train, row_dropping_funcs)\n",
        "\n",
        "df_train.isnull().sum()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "comment           0\n",
              "author            0\n",
              "subreddit         0\n",
              "score             0\n",
              "ups               0\n",
              "downs             0\n",
              "date              0\n",
              "created_utc       0\n",
              "parent_comment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeT_OluY8I3G"
      },
      "source": [
        "#### Text cleaning - Comments only\n",
        "\n",
        "For starters, i'll only explore the comments themselves to see how much sarcasm can be inferred from the text alone.\n",
        "\n",
        "Later on i'll start engineering more features from the rest of the data to see how much the context matters for inferring sarcasm with this data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPlExkPR9pfX"
      },
      "source": [
        "Let's look at a sample from the text to see what we're handling with"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOqAE9M28NM_",
        "outputId": "2c19656c-1dc2-4a3f-e8cb-2fe08efc044c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for index, text in enumerate(df_train['comment'][35:40]):\n",
        "  print('Comment {}:\\n {}'.format(index+1, text))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comment 1:\n",
            " That Stormtrooper pumpkin looks awesome!\n",
            "Comment 2:\n",
            " Yeah, Barry will let this slide.\n",
            "Comment 3:\n",
            " Uh oh, Trigga Trey gonna get some revenge.\n",
            "Comment 4:\n",
            " fuck your opinion\n",
            "Comment 5:\n",
            " we know, but not to loud or the wackos will catch on\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z37Wec8J4Hi",
        "outputId": "1fc85821-5fa1-4621-96e0-af7c95806d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>author</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>score</th>\n",
              "      <th>ups</th>\n",
              "      <th>downs</th>\n",
              "      <th>date</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>parent_comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62983</th>\n",
              "      <td>Agree with ya, it runs better on my 6years old...</td>\n",
              "      <td>GFlunk</td>\n",
              "      <td>PS3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-09</td>\n",
              "      <td>1474168109</td>\n",
              "      <td>I have that one. It sucks.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630544</th>\n",
              "      <td>Yeah, she works me like a rented mule every mo...</td>\n",
              "      <td>comaboy13</td>\n",
              "      <td>MMA</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-07</td>\n",
              "      <td>1436594373</td>\n",
              "      <td>That's really good to know, she'll need it if ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953886</th>\n",
              "      <td>Context?</td>\n",
              "      <td>BigBud77</td>\n",
              "      <td>pics</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2013-05</td>\n",
              "      <td>1367543886</td>\n",
              "      <td>His best friend left today. Not sure if they w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287968</th>\n",
              "      <td>Better quality and without this shit music on ...</td>\n",
              "      <td>Superdraw</td>\n",
              "      <td>formula1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05</td>\n",
              "      <td>1462484952</td>\n",
              "      <td>Albers pulls off an a stunning move (Estoril 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972967</th>\n",
              "      <td>I'm so glad some redditors have taken it upon ...</td>\n",
              "      <td>BuyABowel</td>\n",
              "      <td>MensRights</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-03</td>\n",
              "      <td>1331746883</td>\n",
              "      <td>Explanation requested in AskReddit about r/men...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  comment  ...                                     parent_comment\n",
              "62983   Agree with ya, it runs better on my 6years old...  ...                         I have that one. It sucks.\n",
              "630544  Yeah, she works me like a rented mule every mo...  ...  That's really good to know, she'll need it if ...\n",
              "953886                                           Context?  ...  His best friend left today. Not sure if they w...\n",
              "287968  Better quality and without this shit music on ...  ...  Albers pulls off an a stunning move (Estoril 2...\n",
              "972967  I'm so glad some redditors have taken it upon ...  ...  Explanation requested in AskReddit about r/men...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAv1n5EEVHLX"
      },
      "source": [
        "NLP_ENGINES = {\n",
        "    'simple' : spacy.load(\"en_core_web_sm\", disable=['tagger', 'parser', 'ner']),\n",
        "    'POSs_and_deps' : spacy.load(\"en_core_web_sm\", disable=['ner'])\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjy2NRjl3SST"
      },
      "source": [
        "def tokenize_and_clean_text(doc):\n",
        "  tokenized_processed_text = []\n",
        "  for token in doc:\n",
        "    cleaned_text = token.text.lower()\n",
        "    if token.is_currency:\n",
        "      cleaned_text = clean(cleaned_text, no_currency_symbols = True)\n",
        "    if token.is_digit:\n",
        "      cleaned_text = clean(cleaned_text, no_numbers = True)\n",
        "    if token.like_email:\n",
        "      cleaned_text = clean(cleaned_text, no_emails = True)\n",
        "    if token.like_url:\n",
        "      cleaned_text = clean(cleaned_text, no_urls = True)\n",
        "    tokenized_processed_text.append(cleaned_text)\n",
        "\n",
        "  return tokenized_processed_text"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weaHzGQSNi0V"
      },
      "source": [
        "def simple_text_processing(text):\n",
        "  # spaCy will only handle contractions and will just tokenize the data in general\n",
        "  nlp_engine = NLP_ENGINES['simple']\n",
        "  doc = nlp_engine(text)\n",
        "\n",
        "  return tokenize_and_clean_text(doc)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5cNehPtPlgU"
      },
      "source": [
        "%%time\n",
        "# This takes 9 minutes to run, so i just saved a ready copy of it in a seperate file\n",
        "#df_train['processed comment'] = df_train['comment'].apply(lambda comment: simple_text_processing(comment))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi8rWohS7ULG",
        "outputId": "ad89e894-1199-450e-fff7-0db590263b02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "df_train_processed = pd.read_csv('POSs_and_deps_for_train_state_1.csv', usecols = ['processed comment'])\n",
        "df_train_processed.index = df_train.index\n",
        "df_train = df_train.merge(df_train_processed, how='left', left_index = True, right_index = True) \n",
        "df_train.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>author</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>score</th>\n",
              "      <th>ups</th>\n",
              "      <th>downs</th>\n",
              "      <th>date</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>parent_comment</th>\n",
              "      <th>processed comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62983</th>\n",
              "      <td>Agree with ya, it runs better on my 6years old...</td>\n",
              "      <td>GFlunk</td>\n",
              "      <td>PS3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-09</td>\n",
              "      <td>1474168109</td>\n",
              "      <td>I have that one. It sucks.</td>\n",
              "      <td>['agree', 'with', 'ya', ',', 'it', 'runs', 'be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630544</th>\n",
              "      <td>Yeah, she works me like a rented mule every mo...</td>\n",
              "      <td>comaboy13</td>\n",
              "      <td>MMA</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-07</td>\n",
              "      <td>1436594373</td>\n",
              "      <td>That's really good to know, she'll need it if ...</td>\n",
              "      <td>['yeah', ',', 'she', 'works', 'me', 'like', 'a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953886</th>\n",
              "      <td>Context?</td>\n",
              "      <td>BigBud77</td>\n",
              "      <td>pics</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2013-05</td>\n",
              "      <td>1367543886</td>\n",
              "      <td>His best friend left today. Not sure if they w...</td>\n",
              "      <td>['context', '?']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287968</th>\n",
              "      <td>Better quality and without this shit music on ...</td>\n",
              "      <td>Superdraw</td>\n",
              "      <td>formula1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-05</td>\n",
              "      <td>1462484952</td>\n",
              "      <td>Albers pulls off an a stunning move (Estoril 2...</td>\n",
              "      <td>['better', 'quality', 'and', 'without', 'this'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>972967</th>\n",
              "      <td>I'm so glad some redditors have taken it upon ...</td>\n",
              "      <td>BuyABowel</td>\n",
              "      <td>MensRights</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-03</td>\n",
              "      <td>1331746883</td>\n",
              "      <td>Explanation requested in AskReddit about r/men...</td>\n",
              "      <td>['i', \"'m\", 'so', 'glad', 'some', 'redditors',...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  comment  ...                                  processed comment\n",
              "62983   Agree with ya, it runs better on my 6years old...  ...  ['agree', 'with', 'ya', ',', 'it', 'runs', 'be...\n",
              "630544  Yeah, she works me like a rented mule every mo...  ...  ['yeah', ',', 'she', 'works', 'me', 'like', 'a...\n",
              "953886                                           Context?  ...                                   ['context', '?']\n",
              "287968  Better quality and without this shit music on ...  ...  ['better', 'quality', 'and', 'without', 'this'...\n",
              "972967  I'm so glad some redditors have taken it upon ...  ...  ['i', \"'m\", 'so', 'glad', 'some', 'redditors',...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2KdKs6XXXHP",
        "outputId": "49c43320-8699-473f-c7ba-aaea624e728b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for index, text in enumerate(df_train['processed comment'][35:40]):\n",
        "  print('Comment {}:\\n {}'.format(index+1, text))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comment 1:\n",
            " ['that', 'stormtrooper', 'pumpkin', 'looks', 'awesome', '!']\n",
            "Comment 2:\n",
            " ['yeah', ',', 'barry', 'will', 'let', 'this', 'slide', '.']\n",
            "Comment 3:\n",
            " ['uh', 'oh', ',', 'trigga', 'trey', 'gon', 'na', 'get', 'some', 'revenge', '.']\n",
            "Comment 4:\n",
            " ['fuck', 'your', 'opinion']\n",
            "Comment 5:\n",
            " ['we', 'know', ',', 'but', 'not', 'to', 'loud', 'or', 'the', 'wackos', 'will', 'catch', 'on']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEskcbTYJfqH"
      },
      "source": [
        "# Model Research Process - Comments Only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFvpouHVJjG7"
      },
      "source": [
        "## We begin our research by trying out a basic logistic regression model with different feature sets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhCmO3fvV3lE"
      },
      "source": [
        "### First, a relatively primitive count vectorizer of the comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "961AIbjXWYpT"
      },
      "source": [
        "ctv = CountVectorizer()\n",
        "lr_ctv_clf = LogisticRegression(solver='saga', C=1, n_jobs=-1, verbose=False)\n",
        "ctv_logit_pipeline = Pipeline([('counter', ctv), \n",
        "                               ('logitRegressor', lr_ctv_clf)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79CZ5F5UWZ_Z"
      },
      "source": [
        "%%time\n",
        "ctv_logit_pipeline.fit(df_train, labels_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrADpSmwWzsb"
      },
      "source": [
        "predictions = ctv_logit_pipeline.predict_proba(df_test)\n",
        "print (\"accuracy: %0.3f \" % ctv_logit_pipeline.score(df_test, labels_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hBZQyhDXZqV"
      },
      "source": [
        "### We also test a basic tf-idf vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UkKmNJ8KytE"
      },
      "source": [
        "# We'll first try to create a simple baseline model\n",
        "# Our baseline model will be a logistic regression model, which we'll train on the unigram tf_idf vectors of the original comments text \n",
        "tfv = TfidfVectorizer()\n",
        "\n",
        "tfidf_logit_pipeline = Pipeline([('tf_idf', tfv), \n",
        "                                 ('logitRegressor', lr_tfv_clf)])\n",
        "lr_tfv_clf = LogisticRegression(solver='saga')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbcU2CtBlLGa"
      },
      "source": [
        "%%time\n",
        "tfidf_logit_pipeline.fit(df_train, labels_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkaRSFgSlNh0"
      },
      "source": [
        "predictions = lr_tfv_clf.predict_proba(df_test)\n",
        "\n",
        "print (\"logloss: %0.3f \" % log_loss(labels_test, predictions))\n",
        "print (\"accuracy: %0.3f \" % lr_tfv_clf.score(df_test, labels_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJY5hYrFXgrG"
      },
      "source": [
        "### We try a more sophisticated tf-idf vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDp5qv7mLQaq"
      },
      "source": [
        "# Now let's try to run the same model, but on a more sophisticated tf-idf \n",
        "# This vectorizor is trained on both unigrams and bigrams, and only considers words that were used at least twice\n",
        "tfv = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
        "lr_tfv_clf = LogisticRegression(solver='saga', C=1, n_jobs=4, verbose=0)\n",
        "tfidf_logit_pipeline = Pipeline([('tf_idf', tfv), \n",
        "                                 ('logitRegressor', lr_tfv_clf)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BmVM_nWVEjb"
      },
      "source": [
        "%%time\n",
        "tfidf_logit_pipeline.fit(df_train, labels_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eefMkLZWVGDB"
      },
      "source": [
        "# This model gave us the best performance for this part of the research\n",
        "predictions = tfidf_logit_pipeline.predict_proba(df_test)\n",
        "print (\"logloss: %0.3f \" % log_loss(labels_test, predictions))\n",
        "print (\"accuracy: %0.3f \" % tfidf_logit_pipeline.score(df_test, labels_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqOkWA0NVTBI"
      },
      "source": [
        "# Because it was te best model we tried to understand better what affected his performance\n",
        "eli5.show_weights(estimator=tfidf_logit_pipeline.named_steps['logitRegressor'],\n",
        "                  vec=tfidf_logit_pipeline.named_steps['tf_idf'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5l8ZFfFVnTz"
      },
      "source": [
        "### We theorize that certain pos tags could be strong indicators of sarcasm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38zBk3a5ZZrC"
      },
      "source": [
        "# !python -m spacy download en_core_web_lg\n",
        "nlp = spacy.load('en_core_web_lg', disable=['parser', 'ner', 'textcat'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRUCqQauaDzU"
      },
      "source": [
        "comments_pos_tags = []\n",
        "print('Parsing pos tags...')\n",
        "parsed_comments = [nlp(comment) for comment in tqdm(comments)]\n",
        "for parsed_comment in parsed_comments:\n",
        "  comment_pos_tags = []\n",
        "  for word in parsed_comment:\n",
        "    comment_pos_tags.append(word.tag_)\n",
        "  comments_pos_tags.append(' '.join(comment_pos_tags))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWK-jL7rZUqy"
      },
      "source": [
        "# Now let's try to run the same model, but on a more sophisticated tf-idf \n",
        "tfv = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
        "lr_tfv_clf = LogisticRegression(solver='saga', C=1, n_jobs=4, verbose=0)\n",
        "tfidf_logit_pipeline = Pipeline([('tf_idf', tfv), \n",
        "                                 ('logitRegressor', lr_tfv_clf)])\n",
        "\n",
        "# This vectorizor is trained on both unigrams and bigrams, and only considers words that were used at least twice\n",
        "df_train, df_test, labels_train, labels_test = train_test_split(comments_pos_tags,\n",
        "                                                    full_labels,\n",
        "                                                    random_state=1,\n",
        "                                                    test_size=0.2,\n",
        "                                                    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjZJL0AHZ9wV"
      },
      "source": [
        "%%time\n",
        "tfidf_logit_pipeline.fit(df_train, labels_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GO5wWHeZ-Pf"
      },
      "source": [
        "predictions = tfidf_logit_pipeline.predict_proba(df_test)\n",
        "print (\"logloss: %0.3f \" % log_loss(labels_test, predictions))\n",
        "print (\"accuracy: %0.3f \" % tfidf_logit_pipeline.score(df_test, labels_test))\n",
        "\n",
        "# As it seems, using the plain pos tags as replacements of the words, loses some vital information for the classification\n",
        "eli5.show_weights(estimator=tfidf_logit_pipeline.named_steps['logitRegressor'],\n",
        "                  vec=tfidf_logit_pipeline.named_steps['tf_idf'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}